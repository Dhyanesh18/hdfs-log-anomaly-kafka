{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1b7544b-8199-4585-8878-5425b503a28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df8ef3ea-eb26-4983-b51f-b3811be1cf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"preprocessed/Event_occurrence_matrix.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d10842b4-408d-4974-8ea5-bf07e1f3ed82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BlockId</th>\n",
       "      <th>Label</th>\n",
       "      <th>Type</th>\n",
       "      <th>E1</th>\n",
       "      <th>E2</th>\n",
       "      <th>E3</th>\n",
       "      <th>E4</th>\n",
       "      <th>E5</th>\n",
       "      <th>E6</th>\n",
       "      <th>E7</th>\n",
       "      <th>...</th>\n",
       "      <th>E20</th>\n",
       "      <th>E21</th>\n",
       "      <th>E22</th>\n",
       "      <th>E23</th>\n",
       "      <th>E24</th>\n",
       "      <th>E25</th>\n",
       "      <th>E26</th>\n",
       "      <th>E27</th>\n",
       "      <th>E28</th>\n",
       "      <th>E29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blk_-1608999687919862906</td>\n",
       "      <td>Success</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blk_7503483334202473044</td>\n",
       "      <td>Success</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blk_-3544583377289625738</td>\n",
       "      <td>Fail</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blk_-9073992586687739851</td>\n",
       "      <td>Success</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blk_7854771516489510256</td>\n",
       "      <td>Success</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    BlockId    Label  Type  E1  E2   E3  E4  E5  E6  E7  ...  \\\n",
       "0  blk_-1608999687919862906  Success   NaN   0   0  203   0  10   7   0  ...   \n",
       "1   blk_7503483334202473044  Success   NaN   0   2    1   0   3   0   0  ...   \n",
       "2  blk_-3544583377289625738     Fail  21.0   0   0  203   0   3   0   0  ...   \n",
       "3  blk_-9073992586687739851  Success   NaN   0   3    0   0   3   0   0  ...   \n",
       "4   blk_7854771516489510256  Success   NaN   0   3    1  15   3   0   0  ...   \n",
       "\n",
       "   E20  E21  E22  E23  E24  E25  E26  E27  E28  E29  \n",
       "0    0   10    1   10    0    4   10    0    0    0  \n",
       "1    0    3    1    3    0    0    3    0    0    0  \n",
       "2    1    3    1    3    0    0    3    0    0    0  \n",
       "3    0    3    1    3    0    0    3    0    0    0  \n",
       "4    0    3    1    3    0    0    3    0    0    0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b8a34d7-883b-42b5-93b5-1031ecb53f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>E1</th>\n",
       "      <th>E2</th>\n",
       "      <th>E3</th>\n",
       "      <th>E4</th>\n",
       "      <th>E5</th>\n",
       "      <th>E6</th>\n",
       "      <th>E7</th>\n",
       "      <th>E8</th>\n",
       "      <th>E9</th>\n",
       "      <th>...</th>\n",
       "      <th>E20</th>\n",
       "      <th>E21</th>\n",
       "      <th>E22</th>\n",
       "      <th>E23</th>\n",
       "      <th>E24</th>\n",
       "      <th>E25</th>\n",
       "      <th>E26</th>\n",
       "      <th>E27</th>\n",
       "      <th>E28</th>\n",
       "      <th>E29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16838.000000</td>\n",
       "      <td>575061.000000</td>\n",
       "      <td>575061.000000</td>\n",
       "      <td>575061.000000</td>\n",
       "      <td>575061.000000</td>\n",
       "      <td>575061.000000</td>\n",
       "      <td>575061.000000</td>\n",
       "      <td>575061.000000</td>\n",
       "      <td>575061.000000</td>\n",
       "      <td>575061.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>575061.000000</td>\n",
       "      <td>575061.000000</td>\n",
       "      <td>575061.0</td>\n",
       "      <td>575061.000000</td>\n",
       "      <td>575061.000000</td>\n",
       "      <td>575061.000000</td>\n",
       "      <td>575061.000000</td>\n",
       "      <td>575061.000000</td>\n",
       "      <td>575061.000000</td>\n",
       "      <td>575061.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.375638</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.208736</td>\n",
       "      <td>0.745531</td>\n",
       "      <td>0.619425</td>\n",
       "      <td>2.996607</td>\n",
       "      <td>0.012341</td>\n",
       "      <td>0.005940</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>2.967536</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009642</td>\n",
       "      <td>2.438084</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.427871</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.012176</td>\n",
       "      <td>2.990537</td>\n",
       "      <td>0.001695</td>\n",
       "      <td>0.002240</td>\n",
       "      <td>0.000082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.344260</td>\n",
       "      <td>0.005897</td>\n",
       "      <td>0.580644</td>\n",
       "      <td>2.517178</td>\n",
       "      <td>1.604554</td>\n",
       "      <td>0.220913</td>\n",
       "      <td>0.146923</td>\n",
       "      <td>0.080642</td>\n",
       "      <td>0.009779</td>\n",
       "      <td>0.310178</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101269</td>\n",
       "      <td>1.184490</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.182648</td>\n",
       "      <td>0.002637</td>\n",
       "      <td>0.140481</td>\n",
       "      <td>0.408638</td>\n",
       "      <td>0.041183</td>\n",
       "      <td>0.048865</td>\n",
       "      <td>0.009230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Type             E1             E2             E3  \\\n",
       "count  16838.000000  575061.000000  575061.000000  575061.000000   \n",
       "mean       9.375638       0.000017       0.208736       0.745531   \n",
       "std       11.344260       0.005897       0.580644       2.517178   \n",
       "min        0.000000       0.000000       0.000000       0.000000   \n",
       "25%        3.000000       0.000000       0.000000       0.000000   \n",
       "50%        5.000000       0.000000       0.000000       0.000000   \n",
       "75%        8.000000       0.000000       0.000000       0.000000   \n",
       "max       31.000000       2.000000       4.000000     203.000000   \n",
       "\n",
       "                  E4             E5             E6             E7  \\\n",
       "count  575061.000000  575061.000000  575061.000000  575061.000000   \n",
       "mean        0.619425       2.996607       0.012341       0.005940   \n",
       "std         1.604554       0.220913       0.146923       0.080642   \n",
       "min         0.000000       1.000000       0.000000       0.000000   \n",
       "25%         0.000000       3.000000       0.000000       0.000000   \n",
       "50%         0.000000       3.000000       0.000000       0.000000   \n",
       "75%         0.000000       3.000000       0.000000       0.000000   \n",
       "max        41.000000      13.000000      10.000000       5.000000   \n",
       "\n",
       "                  E8             E9  ...            E20            E21  \\\n",
       "count  575061.000000  575061.000000  ...  575061.000000  575061.000000   \n",
       "mean        0.000085       2.967536  ...       0.009642       2.438084   \n",
       "std         0.009779       0.310178  ...       0.101269       1.184490   \n",
       "min         0.000000       0.000000  ...       0.000000       0.000000   \n",
       "25%         0.000000       3.000000  ...       0.000000       3.000000   \n",
       "50%         0.000000       3.000000  ...       0.000000       3.000000   \n",
       "75%         0.000000       3.000000  ...       0.000000       3.000000   \n",
       "max         2.000000       3.000000  ...       3.000000      13.000000   \n",
       "\n",
       "            E22            E23            E24            E25            E26  \\\n",
       "count  575061.0  575061.000000  575061.000000  575061.000000  575061.000000   \n",
       "mean        1.0       2.427871       0.000007       0.012176       2.990537   \n",
       "std         0.0       1.182648       0.002637       0.140481       0.408638   \n",
       "min         1.0       0.000000       0.000000       0.000000       0.000000   \n",
       "25%         1.0       3.000000       0.000000       0.000000       3.000000   \n",
       "50%         1.0       3.000000       0.000000       0.000000       3.000000   \n",
       "75%         1.0       3.000000       0.000000       0.000000       3.000000   \n",
       "max         1.0      10.000000       1.000000       5.000000      13.000000   \n",
       "\n",
       "                 E27            E28            E29  \n",
       "count  575061.000000  575061.000000  575061.000000  \n",
       "mean        0.001695       0.002240       0.000082  \n",
       "std         0.041183       0.048865       0.009230  \n",
       "min         0.000000       0.000000       0.000000  \n",
       "25%         0.000000       0.000000       0.000000  \n",
       "50%         0.000000       0.000000       0.000000  \n",
       "75%         0.000000       0.000000       0.000000  \n",
       "max         2.000000       4.000000       2.000000  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92f59c3a-1b92-41be-ab36-9c249dfc0ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of                          BlockId    Label  Type  E1  E2   E3  E4  E5  E6  E7  \\\n",
       "0       blk_-1608999687919862906  Success   NaN   0   0  203   0  10   7   0   \n",
       "1        blk_7503483334202473044  Success   NaN   0   2    1   0   3   0   0   \n",
       "2       blk_-3544583377289625738     Fail  21.0   0   0  203   0   3   0   0   \n",
       "3       blk_-9073992586687739851  Success   NaN   0   3    0   0   3   0   0   \n",
       "4        blk_7854771516489510256  Success   NaN   0   3    1  15   3   0   0   \n",
       "...                          ...      ...   ...  ..  ..  ...  ..  ..  ..  ..   \n",
       "575056   blk_1019720114020043203  Success   NaN   0   0    0   0   3   0   0   \n",
       "575057  blk_-2683116845478050414  Success   NaN   0   0    0   0   3   0   0   \n",
       "575058   blk_5595059397348477632  Success   NaN   0   0    0   0   3   0   0   \n",
       "575059   blk_1513937873877967730  Success   NaN   0   0    0   0   3   0   0   \n",
       "575060  blk_-9128742458709757181     Fail   4.0   0   0    0   0   3   0   0   \n",
       "\n",
       "        ...  E20  E21  E22  E23  E24  E25  E26  E27  E28  E29  \n",
       "0       ...    0   10    1   10    0    4   10    0    0    0  \n",
       "1       ...    0    3    1    3    0    0    3    0    0    0  \n",
       "2       ...    1    3    1    3    0    0    3    0    0    0  \n",
       "3       ...    0    3    1    3    0    0    3    0    0    0  \n",
       "4       ...    0    3    1    3    0    0    3    0    0    0  \n",
       "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "575056  ...    0    3    1    3    0    0    3    0    0    0  \n",
       "575057  ...    0    3    1    3    0    0    3    0    0    0  \n",
       "575058  ...    0    3    1    3    0    0    3    0    0    0  \n",
       "575059  ...    0    3    1    3    0    0    3    0    0    0  \n",
       "575060  ...    0    1    1    0    0    0    3    0    3    0  \n",
       "\n",
       "[575061 rows x 32 columns]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bf9df17-0cd8-41d7-ac35-cfcaba6ae1f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "Success    558223\n",
       "Fail        16838\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8ee4d3c-3c86-4db8-b59a-da443f79e721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.0301%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a0a5595-539d-4b5d-903a-dd47a8c5db10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(575061, 32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81a9d87c-2070-4fcc-916d-8f46d4204331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Type\n",
       "5.0     4167\n",
       "31.0    3225\n",
       "3.0     2950\n",
       "0.0     2809\n",
       "4.0     1240\n",
       "1.0      953\n",
       "21.0     724\n",
       "7.0      476\n",
       "12.0     130\n",
       "8.0       45\n",
       "9.0       34\n",
       "16.0      22\n",
       "13.0      10\n",
       "18.0       9\n",
       "22.0       9\n",
       "19.0       8\n",
       "20.0       7\n",
       "27.0       3\n",
       "24.0       3\n",
       "11.0       3\n",
       "17.0       3\n",
       "10.0       3\n",
       "25.0       2\n",
       "28.0       1\n",
       "23.0       1\n",
       "30.0       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_notna = df[df[\"Type\"].notna()]\n",
    "df_notna[\"Type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a885c31c-fee5-4bc6-89aa-977d59a7c6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = df.drop(columns=[\"BlockId\", \"Label\", \"Type\"])\n",
    "\n",
    "X = X.fillna(0)\n",
    "X_scaled = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5e8fc82c-ca39-46c2-a01c-7756aa201fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.94869554e-03, -3.59490884e-01,  8.03497725e+01, ...,\n",
       "        -4.11687898e-02, -4.58358638e-02, -8.85441522e-03],\n",
       "       [-2.94869554e-03,  3.08496223e+00,  1.01092939e-01, ...,\n",
       "        -4.11687898e-02, -4.58358638e-02, -8.85441522e-03],\n",
       "       [-2.94869554e-03, -3.59490884e-01,  8.03497725e+01, ...,\n",
       "        -4.11687898e-02, -4.58358638e-02, -8.85441522e-03],\n",
       "       ...,\n",
       "       [-2.94869554e-03, -3.59490884e-01, -2.96177752e-01, ...,\n",
       "        -4.11687898e-02, -4.58358638e-02, -8.85441522e-03],\n",
       "       [-2.94869554e-03, -3.59490884e-01, -2.96177752e-01, ...,\n",
       "        -4.11687898e-02, -4.58358638e-02, -8.85441522e-03],\n",
       "       [-2.94869554e-03, -3.59490884e-01, -2.96177752e-01, ...,\n",
       "        -4.11687898e-02,  6.13479941e+01, -8.85441522e-03]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d2a49d06-09a7-4ff6-b839-9c4e228fc1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "iso = IsolationForest(\n",
    "    n_estimators=300,         # more trees for stability\n",
    "    max_samples=256,          # default; small subsample size\n",
    "    max_features=1.0,         # use all features\n",
    "    contamination=0.0292,     # match your true anomaly rate\n",
    "    bootstrap=False,          # no need for replacement\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "y_pred = iso.fit_predict(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e53ecacd-ab95-40ea-8d95-f74d77e84288",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = (df[\"Label\"]==\"Fail\").astype(int)\n",
    "\n",
    "y_pred = pd.Series(y_pred).map({1:0, -1:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bbb9e6cf-e28e-40c0-a9b0-5d7754512b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9878    0.9942    0.9910    558223\n",
      "           1     0.7550    0.5930    0.6643     16838\n",
      "\n",
      "    accuracy                         0.9824    575061\n",
      "   macro avg     0.8714    0.7936    0.8276    575061\n",
      "weighted avg     0.9810    0.9824    0.9814    575061\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d04f00b9-9b14-4503-aac7-8d2e962ec12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9904    0.9997    0.9950    111645\n",
      "           1     0.9854    0.6793    0.8042      3368\n",
      "\n",
      "    accuracy                         0.9903    115013\n",
      "   macro avg     0.9879    0.8395    0.8996    115013\n",
      "weighted avg     0.9903    0.9903    0.9894    115013\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Features and labels\n",
    "X = df.drop(columns=[\"BlockId\", \"Label\", \"Type\", \"E20\",\"E26\",\"E27\",\"E11\"])\n",
    "y = df[\"Label\"].map({\"Success\": 0, \"Fail\": 1})\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Random Forest with class weights\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "acec1f87-e470-4ee7-bb9d-c763b639d7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E20    0.339088\n",
      "E26    0.136609\n",
      "E27    0.081055\n",
      "E11    0.069123\n",
      "E5     0.068362\n",
      "E9     0.062788\n",
      "E28    0.044385\n",
      "E21    0.043234\n",
      "E13    0.041403\n",
      "E18    0.028701\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "feat_importances = pd.Series(clf.feature_importances_, index=X.columns)\n",
    "print(feat_importances.sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7bc07aa6-350b-4cc7-9356-6841f7146051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random_forest_hdfs.pkl']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(clf, \"random_forest_hdfs.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dced806d-8e81-4792-9e29-52838bbcb07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/train.py\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_model(data_path, version):\n",
    "    # Load dataset\n",
    "    df = pd.read_csv(data_path)\n",
    "    X = df.drop(columns=[\"BlockId\", \"Label\", \"Type\"])\n",
    "    y = df[\"Label\"].map({\"Success\": 0, \"Fail\": 1})\n",
    "\n",
    "    # Split train/val\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # Train model\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate\n",
    "    y_pred = clf.predict(X_val)\n",
    "    report = classification_report(y_val, y_pred, digits=4, output_dict=True)\n",
    "    print(classification_report(y_val, y_pred, digits=4))\n",
    "\n",
    "    # Save model\n",
    "    model_path = f\"models/model_{version}.joblib\"\n",
    "    joblib.dump(clf, model_path)\n",
    "\n",
    "    # Log to MLflow\n",
    "    mlflow.set_experiment(\"hdfs_anomaly_detection\")\n",
    "    with mlflow.start_run(run_name=f\"rf_{version}\"):\n",
    "        mlflow.log_param(\"n_estimators\", 200)\n",
    "        mlflow.log_param(\"class_weight\", \"balanced\")\n",
    "        mlflow.log_param(\"train_size\", len(X_train))\n",
    "        mlflow.log_param(\"val_size\", len(X_val))\n",
    "        mlflow.log_metric(\"precision_fail\", report[\"1\"][\"precision\"])\n",
    "        mlflow.log_metric(\"recall_fail\", report[\"1\"][\"recall\"])\n",
    "        mlflow.log_metric(\"f1_fail\", report[\"1\"][\"f1-score\"])\n",
    "        mlflow.sklearn.log_model(clf, name=\"random_forest_model\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--data\", required=True, help=\"Path to CSV dataset\")\n",
    "    parser.add_argument(\"--version\", required=True, help=\"Model version (e.g., v1, v2)\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    train_model(args.data, args.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa95322-7693-40a5-83d7-02a9546c2051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (402542, 32)\n",
      "Test shape: (172519, 32)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"preprocessed/Event_occurrence_matrix.csv\")\n",
    "\n",
    "\n",
    "train_df, test_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=df[\"Label\"] \n",
    ")\n",
    "\n",
    "# Save to CSV\n",
    "train_df.to_csv(\"preprocessed/Event_occurrence_matrix_train.csv\", index=False)\n",
    "test_df.to_csv(\"preprocessed/Event_occurrence_matrix_test.csv\", index=False)\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb58136-fa87-470a-b4f9-d7b2f2aeb13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/27 20:28:37 INFO mlflow.tracking.fluent: Experiment with name 'hdfs_anomaly_detection' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9999    0.9999     78152\n",
      "           1     0.9966    0.9996    0.9981      2357\n",
      "\n",
      "    accuracy                         0.9999     80509\n",
      "   macro avg     0.9983    0.9997    0.9990     80509\n",
      "weighted avg     0.9999    0.9999    0.9999     80509\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ENVS\\myenv\\lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "D:\\ENVS\\myenv\\lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a36171b6ca8148fd92fe144200d93f42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "os.makedirs(\"mlruns\", exist_ok=True)\n",
    "\n",
    "mlflow.set_tracking_uri(\"file:./mlruns\")\n",
    "\n",
    "def train_model(data_path, version):\n",
    "    # Load dataset\n",
    "    df = pd.read_csv(data_path)\n",
    "    X = df.drop(columns=[\"BlockId\", \"Label\", \"Type\"]).astype(\"float64\")\n",
    "    y = df[\"Label\"].map({\"Success\": 0, \"Fail\": 1})\n",
    "\n",
    "    # Train/test split\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # Train model\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate\n",
    "    y_pred = clf.predict(X_val)\n",
    "    report = classification_report(y_val, y_pred, digits=4, output_dict=True)\n",
    "    print(classification_report(y_val, y_pred, digits=4))\n",
    "\n",
    "    # Ensure models folder exists\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "    # Save model with joblib (optional since MLflow already logs it)\n",
    "    model_path = f\"models/model_{version}.joblib\"\n",
    "    joblib.dump(clf, model_path)\n",
    "\n",
    "    # Log to MLflow\n",
    "    mlflow.set_experiment(\"hdfs_anomaly_detection\")\n",
    "    with mlflow.start_run(run_name=f\"rf_{version}\"):\n",
    "        mlflow.log_param(\"n_estimators\", 200)\n",
    "        mlflow.log_param(\"class_weight\", \"balanced\")\n",
    "        mlflow.log_param(\"train_size\", len(X_train))\n",
    "        mlflow.log_param(\"val_size\", len(X_val))\n",
    "        mlflow.log_metric(\"precision_fail\", report[\"1\"][\"precision\"])\n",
    "        mlflow.log_metric(\"recall_fail\", report[\"1\"][\"recall\"])\n",
    "        mlflow.log_metric(\"f1_fail\", report[\"1\"][\"f1-score\"])\n",
    "\n",
    "        # Fix warning: use \"name\" instead of deprecated artifact_path\n",
    "        mlflow.sklearn.log_model(clf, name=\"random_forest_model\", \n",
    "                                 input_example=X_train.iloc[:1])\n",
    "\n",
    "    return clf\n",
    "\n",
    "# Run it\n",
    "clf = train_model(\"preprocessed/Event_occurrence_matrix_train.csv\", version=\"v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "903bfc2b-879f-471e-ac63-6b27b4e1c552",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"preprocessed/Event_occurrence_matrix_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97acbd8d-a0c2-47c1-9b9d-9d6146366a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"Label\"]!=\"Fail\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0234c790-0b25-4188-886e-590487f1e146",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7aa72ed-270b-4627-9483-55f2b992ee43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f88ee3c1-49e0-4f5b-bd5a-467b02a76ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim=29, latent_dim=8):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, latent_dim)\n",
    "            \n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, input_dim)\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "    def decode(self, x):\n",
    "        return self.decoder(x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7721c4d5-8562-400b-b970-395a86e8bc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "46feb942-f203-4022-b2c9-b346a6c2579c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bcfc02f8-9a76-447a-af30-ce2419150c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.drop(columns=[\"BlockId\",\"Label\", \"Type\"]).values.astype(np.float32)\n",
    "mean = X_train.mean(axis=0)\n",
    "std = X_train.std(axis=0)\n",
    "X_train_norm = (X_train - mean) / (std + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ebdc799d-d7d3-4889-aaae-b370f937dc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train_norm, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cf6bbb73-bc57-4801-b37b-c30c42752c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000, -0.3596, -0.2902,  ..., -0.0028, -0.0051,  0.0000],\n",
       "        [ 0.0000, -0.3596, -0.2902,  ..., -0.0028, -0.0051,  0.0000],\n",
       "        [ 0.0000, -0.3596, -0.2902,  ..., -0.0028, -0.0051,  0.0000],\n",
       "        ...,\n",
       "        [ 0.0000, -0.3596, -0.2902,  ..., -0.0028, -0.0051,  0.0000],\n",
       "        [ 0.0000,  1.3658, -0.2902,  ..., -0.0028, -0.0051,  0.0000],\n",
       "        [ 0.0000, -0.3596, -0.2902,  ..., -0.0028, -0.0051,  0.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea922aee-b86b-49a7-bf36-46586abf0c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9fd5b3fe-1660-4639-8a33-6cad79efda27",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d127c21c-c3a0-479d-bafa-0374421cbff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c58feda1-78e7-4eb1-911e-31f314aaaeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_train_tensor.shape[1]\n",
    "latent_dim = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8485764b-9f30-43c2-9999-30a8a80ef3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae = Autoencoder(input_dim=input_dim, latent_dim=latent_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8de7ee76-8a80-4975-83ca-48c6961e6330",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(ae.parameters(), lr=1e-3, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "195c66f5-cc9b-4a98-870d-0709afb25256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch [1/50], Loss: 0.098237\n",
      "Epoch [2/50], Loss: 0.054070\n",
      "Epoch [3/50], Loss: 0.028284\n",
      "Epoch [4/50], Loss: 0.026323\n",
      "Epoch [5/50], Loss: 0.018392\n",
      "Epoch [6/50], Loss: 0.019492\n",
      "Epoch [7/50], Loss: 0.016776\n",
      "Epoch [8/50], Loss: 0.014679\n",
      "Epoch [9/50], Loss: 0.016495\n",
      "Epoch [10/50], Loss: 0.012350\n",
      "Epoch [11/50], Loss: 0.021156\n",
      "Epoch [12/50], Loss: 0.013655\n",
      "Epoch [13/50], Loss: 0.011100\n",
      "Epoch [14/50], Loss: 0.017192\n",
      "Epoch [15/50], Loss: 0.013984\n",
      "Epoch [16/50], Loss: 0.009942\n",
      "Epoch [17/50], Loss: 0.009981\n",
      "Epoch [18/50], Loss: 0.015739\n",
      "Epoch [19/50], Loss: 0.011666\n",
      "Epoch [20/50], Loss: 0.012192\n",
      "Epoch [21/50], Loss: 0.007643\n",
      "Epoch [22/50], Loss: 0.011559\n",
      "Epoch [23/50], Loss: 0.011146\n",
      "Epoch [24/50], Loss: 0.012799\n",
      "Epoch [25/50], Loss: 0.009426\n",
      "Epoch [26/50], Loss: 0.013901\n",
      "Epoch [27/50], Loss: 0.011011\n",
      "Epoch [28/50], Loss: 0.009413\n",
      "Epoch [29/50], Loss: 0.014790\n",
      "Epoch [30/50], Loss: 0.010510\n",
      "Epoch [31/50], Loss: 0.006667\n",
      "Epoch [32/50], Loss: 0.011198\n",
      "Epoch [33/50], Loss: 0.008191\n",
      "Epoch [34/50], Loss: 0.008108\n",
      "Epoch [35/50], Loss: 0.018701\n",
      "Epoch [36/50], Loss: 0.005492\n",
      "Epoch [37/50], Loss: 0.014852\n",
      "Epoch [38/50], Loss: 0.004800\n",
      "Epoch [39/50], Loss: 0.009052\n",
      "Epoch [40/50], Loss: 0.013351\n",
      "Epoch [41/50], Loss: 0.004793\n",
      "Epoch [42/50], Loss: 0.011344\n",
      "Epoch [43/50], Loss: 0.007054\n",
      "Epoch [44/50], Loss: 0.008466\n",
      "Epoch [45/50], Loss: 0.009930\n",
      "Epoch [46/50], Loss: 0.013521\n",
      "Epoch [47/50], Loss: 0.009781\n",
      "Epoch [48/50], Loss: 0.003694\n",
      "Epoch [49/50], Loss: 0.008368\n",
      "Epoch [50/50], Loss: 0.010337\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    ae.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for (x_batch,) in train_loader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        x_hat = ae(x_batch)\n",
    "        loss = criterion(x_hat, x_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * x_batch.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "41bc42c3-edda-4810-8c4c-8c4149bf0d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly detection threshold: 0.0011698033194988966\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       1.00      0.98      0.99    167468\n",
      "     Anomaly       0.62      1.00      0.77      5051\n",
      "\n",
      "    accuracy                           0.98    172519\n",
      "   macro avg       0.81      0.99      0.88    172519\n",
      "weighted avg       0.99      0.98      0.98    172519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "df_val = pd.read_csv(\"preprocessed/Event_occurrence_matrix_test.csv\")\n",
    "\n",
    "X_val = df_val.drop(columns=[\"BlockId\",\"Label\",\"Type\"]).values.astype(np.float32)\n",
    "y_val = (df_val[\"Label\"] != \"Success\").astype(int).values \n",
    "\n",
    "X_val_norm = (X_val - mean) / (std + 1e-8)\n",
    "X_val_tensor = torch.tensor(X_val_norm, dtype=torch.float32).to(device)\n",
    "\n",
    "\n",
    "ae.eval()\n",
    "with torch.no_grad():\n",
    "    recon_val = ae(X_val_tensor)\n",
    "    errors_val = ((recon_val - X_val_tensor)**2).mean(dim=1).cpu().numpy()\n",
    "\n",
    "\n",
    "normal_mask = (y_val == 0)\n",
    "threshold = np.percentile(errors_val[normal_mask], 98.0)\n",
    "print(\"Anomaly detection threshold:\", threshold)\n",
    "\n",
    "\n",
    "anomaly_pred = (errors_val > threshold).astype(int)\n",
    "\n",
    "print(classification_report(y_val, anomaly_pred, target_names=[\"Normal\",\"Anomaly\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0ebdc6d8-dab0-4292-a678-b5b7ef9cff12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly detection threshold: 0.0021631440613418818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       1.00      0.99      1.00    167468\n",
      "     Anomaly       0.80      1.00      0.89      5051\n",
      "\n",
      "    accuracy                           0.99    172519\n",
      "   macro avg       0.90      1.00      0.94    172519\n",
      "weighted avg       0.99      0.99      0.99    172519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "threshold = np.percentile(errors_val[normal_mask], 99.0)\n",
    "print(\"Anomaly detection threshold:\", threshold)\n",
    "\n",
    "\n",
    "anomaly_pred = (errors_val > threshold).astype(int)\n",
    "\n",
    "print(classification_report(y_val, anomaly_pred, target_names=[\"Normal\",\"Anomaly\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1e0f50f4-d893-472b-a305-d70fa5f8306d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly detection threshold: 0.005830070935189724\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       1.00      1.00      1.00    167468\n",
      "     Anomaly       0.89      1.00      0.94      5051\n",
      "\n",
      "    accuracy                           1.00    172519\n",
      "   macro avg       0.95      1.00      0.97    172519\n",
      "weighted avg       1.00      1.00      1.00    172519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "threshold = np.percentile(errors_val[normal_mask], 99.5)\n",
    "print(\"Anomaly detection threshold:\", threshold)\n",
    "\n",
    "anomaly_pred = (errors_val > threshold).astype(int)\n",
    "\n",
    "print(classification_report(y_val, anomaly_pred, target_names=[\"Normal\",\"Anomaly\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d5e708ef-97ca-4943-87b2-45ba83abbc2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly detection threshold: 0.06730180978775024\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       1.00      1.00      1.00    167468\n",
      "     Anomaly       0.95      1.00      0.97      5051\n",
      "\n",
      "    accuracy                           1.00    172519\n",
      "   macro avg       0.97      1.00      0.99    172519\n",
      "weighted avg       1.00      1.00      1.00    172519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "threshold = np.percentile(errors_val[normal_mask], 99.8)\n",
    "print(\"Anomaly detection threshold:\", threshold)\n",
    "\n",
    "\n",
    "anomaly_pred = (errors_val > threshold).astype(int)\n",
    "\n",
    "print(classification_report(y_val, anomaly_pred, target_names=[\"Normal\",\"Anomaly\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "991d68d4-fa66-461c-b3ca-047eb7cbe27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly detection threshold: 0.22368356585502625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       1.00      1.00      1.00    167468\n",
      "     Anomaly       0.98      0.99      0.98      5051\n",
      "\n",
      "    accuracy                           1.00    172519\n",
      "   macro avg       0.99      0.99      0.99    172519\n",
      "weighted avg       1.00      1.00      1.00    172519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "threshold = np.percentile(errors_val[normal_mask], 99.9)\n",
    "print(\"Anomaly detection threshold:\", threshold)\n",
    "\n",
    "\n",
    "anomaly_pred = (errors_val > threshold).astype(int)\n",
    "\n",
    "print(classification_report(y_val, anomaly_pred, target_names=[\"Normal\",\"Anomaly\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e878b467-ad9e-4349-a65f-5bc3eb03c3fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
